{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "        isExist = os.path.exists(path)\n",
    "        if not isExist:\n",
    "            os.makedirs(path, exist_ok = False)\n",
    "            print(\"New directory is created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     open    high    low  close  tick_volume\n",
      "0  310.30  314.40  310.0  313.5          561\n",
      "1  312.60  315.20  311.9  314.3          491\n",
      "2  313.40  314.20  311.8  312.9          431\n",
      "3  312.25  313.65  308.9  309.9          716\n",
      "4  309.39  310.90  306.3  308.2          802\n"
     ]
    }
   ],
   "source": [
    "class DataFormatting():\n",
    "  \n",
    "    def __init__(self):\n",
    "       \n",
    "        self.df_data = None\n",
    "        self.df_datetime = None\n",
    "\n",
    "    def dataset(df):\n",
    "\n",
    "        # converting time colum from object type to datetime format\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        # splitting the dataframe in to X and y \n",
    "        df_data = df[['open','high','low','close','tick_volume']]\n",
    "        df_datetime =df[['time']]\n",
    "\n",
    "        return df_data, df_datetime\n",
    "\n",
    "\n",
    "data = pd.read_csv('../data/gold_mt5.csv',index_col=[0]) \n",
    "\n",
    "data_init = DataFormatting()\n",
    "df_data, df_datetime = DataFormatting.dataset(data)\n",
    "print(df_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_days = 5\n",
    "\n",
    "forecast_date = pd.date_range(list(df_datetime.time)[-1], periods = future_days, freq = '1d').tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2022-07-28 00:00:00', freq='D'),\n",
       " Timestamp('2022-07-29 00:00:00', freq='D'),\n",
       " Timestamp('2022-07-30 00:00:00', freq='D'),\n",
       " Timestamp('2022-07-31 00:00:00', freq='D'),\n",
       " Timestamp('2022-08-01 00:00:00', freq='D')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         open     high      low    close  tick_volume\n",
      "4499  1291.91  1293.77  1279.67  1284.54        69923\n",
      "4500  1283.21  1285.92  1251.96  1257.16        99537\n",
      "4501  1257.03  1284.76  1256.42  1283.33        82008\n",
      "4502  1282.10  1283.40  1266.41  1273.99        78714\n",
      "4503  1273.45  1285.76  1255.48  1260.31        84037          open     high      low    close  tick_volume\n",
      "4504  1260.34  1272.52  1256.67  1269.39        81582\n",
      "4505  1268.51  1274.05  1256.35  1264.64        76837\n",
      "4506  1264.50  1268.74  1228.29  1233.65        86849\n",
      "4507  1235.94  1243.64  1234.30  1239.14        53069\n",
      "4508  1238.73  1245.85  1230.98  1233.38        60960          open     high      low    close  tick_volume\n",
      "5786  1562.49  1575.83  1556.56  1571.43       115510\n",
      "5787  1581.21  1588.51  1575.90  1581.86       161267\n",
      "5788  1581.58  1583.07  1565.57  1567.88       126826\n",
      "5789  1566.89  1578.04  1563.40  1576.76       111628\n",
      "5790  1576.86  1585.99  1572.30  1573.89       163993          open     high      low    close  tick_volume\n",
      "5791  1574.18  1590.44  1570.98  1589.17       161457\n",
      "5792  1593.12  1593.63  1569.70  1576.67       156669\n",
      "5793  1576.76  1579.68  1549.08  1552.70       132568\n",
      "5794  1552.59  1562.42  1547.51  1556.61       153561\n",
      "5795  1555.94  1568.28  1552.54  1566.61       128650          open     high      low    close  tick_volume\n",
      "6430  1717.75  1739.25  1712.89  1727.38        83882\n",
      "6431  1726.70  1736.22  1714.74  1719.64        77996\n",
      "6432  1719.11  1728.16  1713.62  1717.20        76775\n",
      "6433  1717.41  1740.24  1711.50  1734.33        81867\n",
      "6434  1734.65  1741.68  1734.07  1737.30        18408\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data, train_split=0.7):\n",
    "\n",
    "    \"\"\" This function will split the dataframe into training and testing set.\n",
    "    Inputs: data: Pandas DatFrame\n",
    "            train_split: default is set to 0.9. Its a ratio to split the trining and testing datset.\n",
    "    \"\"\"\n",
    "    split = int(train_split*len(data)) # for training\n",
    "    split_test = int(0.90*len(data))\n",
    "    X_train = data.iloc[:split,:]\n",
    "    X_val = data.iloc[split:split_test,:]\n",
    "    X_test = data.iloc[split_test:,:]\n",
    "\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "X_train, X_val, X_test = train_test_split(df_data, train_split=0.7)\n",
    "\n",
    "print(X_train.tail(), X_val.head(), X_val.tail(),X_test.head(), X_test.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Normalize():\n",
    "    \n",
    "#     \"\"\" class Normalize uses standard scaler method to normalize the dataset\"\"\"\n",
    "#     def __init__(self):\n",
    "\n",
    "#         self.data_fit_transformed = None\n",
    "#         self.data_inverse_transformed = None\n",
    "\n",
    "#     def fit_transform(self, data):\n",
    "\n",
    "#         # initialize StandartScaler()\n",
    "#         scaler = StandardScaler()\n",
    "#         # fit the method on the dataset\n",
    "#         scaler = scaler.fit(data)\n",
    "#         # transform the dataset\n",
    "#         data_fit_transformed = scaler.transform(data)\n",
    "\n",
    "#         return data_fit_transformed\n",
    "\n",
    "#     def transform(self,data):\n",
    "    \n",
    "#         # initialize StandardScaler()\n",
    "#         scaler = StandardScaler()\n",
    "\n",
    "#         # transform the dataset\n",
    "#         data_fit_transformed = scaler.transform(data)\n",
    "\n",
    "#         return data_fit_transformed\n",
    "\n",
    "#     def inverse_transform(self, data):\n",
    "\n",
    "#         # initialize StandartScaler()\n",
    "#         scaler = StandardScaler()\n",
    "#         # inverse transform the dataset\n",
    "#         data_inverse_transformed = scaler.inverse_transform(data)\n",
    "        \n",
    "#         return data_inverse_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96366767 -0.9621959  -0.95901081 -0.95840204 -0.71730974]\n",
      " [-0.95902447 -0.96059173 -0.95514351 -0.95678648 -0.72034248]\n",
      " [-0.95740944 -0.96259695 -0.95534705 -0.95961372 -0.72294197]\n",
      " [-0.95973104 -0.96369981 -0.96124978 -0.96567209 -0.71059439]\n",
      " [-0.96550476 -0.96921414 -0.96654188 -0.96910517 -0.70686845]] [[0.95425693 0.95903778 0.96786237 0.97197787 2.79291116]\n",
      " [0.97075039 0.96210576 0.96721104 0.96238544 2.58733485]\n",
      " [0.96265507 0.95145808 0.91009709 0.89980243 3.02110303]\n",
      " [0.90499863 0.90112726 0.92232997 0.91088926 1.55759034]\n",
      " [0.91063103 0.90555878 0.91557237 0.89925718 1.89946655]] [[1.58783179 1.59653477 1.60761594 1.61776022 6.2534818 ]\n",
      " [1.62606754 1.6029314  1.6050106  1.59251699 6.04604253]\n",
      " [1.59304025 1.57495869 1.56304019 1.54411058 5.00187084]\n",
      " [1.54424626 1.54034873 1.55984458 1.55200666 5.91138896]\n",
      " [1.55100919 1.55209927 1.57008275 1.57220124 4.83212417]]\n"
     ]
    }
   ],
   "source": [
    "class Normalize():\n",
    "\n",
    "    \"\"\" class Normalize uses standard scaler method to normalize the dataset\"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        self.data_fit_transformed = None\n",
    "        self.data_inverse_transformed = None\n",
    "\n",
    "    def fit_transform(self, data_train, data_val, data_test):\n",
    "\n",
    "        # initialize StandartScaler()\n",
    "        scaler = StandardScaler()\n",
    "        # define transformer\n",
    "        transformer = [('standard_scaler', StandardScaler(),['open','high','low','close','tick_volume'])]\n",
    "        # define column transformer\n",
    "        column_transformer = ColumnTransformer(transformers = transformer)\n",
    "        # fit and transform training data\n",
    "        data_fit_transformed = column_transformer.fit_transform(data_train)\n",
    "        # # fit the method on the dataset\n",
    "        # scaler = scaler.fit(data)\n",
    "        # # transform the dataset\n",
    "        # data_fit_transformed = scaler.transform(data)\n",
    "        val_transformed = column_transformer.transform(data_val)\n",
    "        test_transformed = column_transformer.transform(data_test)\n",
    "        return data_fit_transformed, val_transformed, test_transformed\n",
    "\n",
    "    def transform(self,data):\n",
    "\n",
    "        # initialize StandartScaler()\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # transform the dataset\n",
    "        data_fit_transformed = scaler.transform(data)\n",
    "\n",
    "        return data_fit_transformed\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "\n",
    "        # initialize StandartScaler()\n",
    "        scaler = StandardScaler()\n",
    "        # inverse transform the dataset\n",
    "        data_inverse_transformed = scaler.inverse_transform(data)\n",
    "        \n",
    "        return data_inverse_transformed\n",
    "\n",
    "# normalize\n",
    "scaler_init = Normalize()\n",
    "data_fit_transformed, val_transformed, test_transformed = scaler_init.fit_transform(X_train, X_val, X_test)\n",
    "print(data_fit_transformed[0:5], val_transformed[0:5], test_transformed[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(data, lags = 5):\n",
    "\n",
    "    \"\"\" this function transforms dataframe to required input shape for the model.\n",
    "    It required 2 input arguments:\n",
    "    1. data: this will be the pandas dataframe\n",
    "    2. lags: how many previous price points to be used to predict the next future value, in\n",
    "    this case the default is set to 5 for 'XAUUSD' commodity\"\"\"\n",
    "\n",
    "    # initialize lists to store the dataset\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for i in range(lags, len(data)):\n",
    "        X_data.append(data[i-lags: i, 0: data.shape[1]])\n",
    "        y_data.append(data[i,3:4]) # extracts close price with specific lag as price to be predicted.\n",
    "\n",
    "    # convert the list to numpy array\n",
    "\n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return X_data, y_data\n",
    "\n",
    "\n",
    "X_data, y_data = data_transformation(data_fit_transformed, lags = 5)\n",
    "X_val_data, y_val_data =  data_transformation(val_transformed, lags = 5)\n",
    "X_test_data, y_test_data =  data_transformation(test_transformed, lags = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4499 5 5 1\n"
     ]
    }
   ],
   "source": [
    "print(X_data.shape[0],X_data.shape[1],X_data.shape[2],y_data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model():\n",
    "    \n",
    "\n",
    "    def __init__(self,n_hidden_layers, units, dropout, train_data_X, train_data_y, epochs):\n",
    "\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.units = units\n",
    "        self.dropout = dropout\n",
    "        self.train_data_X = train_data_X\n",
    "        self.train_data_y = train_data_y\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        # first lstm layer\n",
    "        model.add(LSTM(self.units, activation='relu', input_shape=(self.train_data_X.shape[1], self.train_data_X.shape[2]), return_sequences=True))\n",
    "        # building hidden layers\n",
    "        for i in range(1, self.n_hidden_layers):\n",
    "            # for the last layer as the return sequence is False\n",
    "            if i == self.n_hidden_layers -1:\n",
    "                model.add(LSTM(int(self.units/(2**i)),  activation='relu', return_sequences=False))\n",
    "            else:\n",
    "                model.add(LSTM(int(self.units/(2**i)),  activation='relu', return_sequences=True))\n",
    "        # adding droupout layer\n",
    "        model.add(Dropout(self.dropout))\n",
    "        # final layer\n",
    "        model.add(Dense(self.train_data_y.shape[1]))\n",
    "        return model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/5\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.2691 - root_mean_squared_error: 0.5188 - mean_absolute_error: 0.3852 - mean_absolute_percentage_error: 58.5194INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220EB476F50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220E90F3670> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022093F45B10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 23s 36ms/step - loss: 0.2691 - root_mean_squared_error: 0.5188 - mean_absolute_error: 0.3852 - mean_absolute_percentage_error: 58.5194 - val_loss: 4.6575 - val_root_mean_squared_error: 2.1581 - val_mean_absolute_error: 1.2597 - val_mean_absolute_percentage_error: 124.0693\n",
      "Epoch 2/5\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.0544 - root_mean_squared_error: 0.2333 - mean_absolute_error: 0.1620 - mean_absolute_percentage_error: 31.9824INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220EB476F50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220E90F3670> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022093F45B10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 20s 36ms/step - loss: 0.0544 - root_mean_squared_error: 0.2333 - mean_absolute_error: 0.1620 - mean_absolute_percentage_error: 31.9824 - val_loss: 1.8314 - val_root_mean_squared_error: 1.3533 - val_mean_absolute_error: 0.8410 - val_mean_absolute_percentage_error: 83.0830\n",
      "Epoch 3/5\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.0532 - root_mean_squared_error: 0.2307 - mean_absolute_error: 0.1573 - mean_absolute_percentage_error: 32.7881INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220EB476F50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220E90F3670> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022093F45B10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 26s 45ms/step - loss: 0.0532 - root_mean_squared_error: 0.2307 - mean_absolute_error: 0.1573 - mean_absolute_percentage_error: 32.7881 - val_loss: 0.5029 - val_root_mean_squared_error: 0.7092 - val_mean_absolute_error: 0.4800 - val_mean_absolute_percentage_error: 47.4891\n",
      "Epoch 4/5\n",
      "562/563 [============================>.] - ETA: 0s - loss: 0.0389 - root_mean_squared_error: 0.1971 - mean_absolute_error: 0.1385 - mean_absolute_percentage_error: 32.6711INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220EB476F50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220E90F3670> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022093F45B10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 24s 42ms/step - loss: 0.0389 - root_mean_squared_error: 0.1971 - mean_absolute_error: 0.1385 - mean_absolute_percentage_error: 32.6618 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233 - val_mean_absolute_error: 0.0900 - val_mean_absolute_percentage_error: 8.6515\n",
      "Epoch 5/5\n",
      "562/563 [============================>.] - ETA: 0s - loss: 0.0346 - root_mean_squared_error: 0.1860 - mean_absolute_error: 0.1320 - mean_absolute_percentage_error: 27.7087INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Model_Outputs/2022_07_30/model_lstm128\\model_checkpoint\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220EB476F50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000220E90F3670> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022093F45B10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 25s 44ms/step - loss: 0.0346 - root_mean_squared_error: 0.1860 - mean_absolute_error: 0.1320 - mean_absolute_percentage_error: 27.7014 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186 - val_mean_absolute_error: 0.0619 - val_mean_absolute_percentage_error: 5.9191\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    n_hidden_layers = 3\n",
    "    units = 128\n",
    "    dropout = 0.2\n",
    "    train_data_X = X_data \n",
    "    train_data_y = y_data\n",
    "    epochs = 5\n",
    "\n",
    "    # creating main folder\n",
    "    today = datetime.now()\n",
    "    today  = today.strftime('%Y_%m_%d')\n",
    "    path = '../Model_Outputs/'+ today\n",
    "    create_dir(path)\n",
    " \n",
    "    # creating directory to save model and its output\n",
    "    folder = 'model_lstm'+ str(units)\n",
    "    path_main = path + '/'+ folder\n",
    "    create_dir(path_main)\n",
    "\n",
    "    # creating directory to save all the metric data\n",
    "    folder = 'metrics'\n",
    "    path_metrics = path_main +'/'+ folder\n",
    "    create_dir(path_metrics)\n",
    "\n",
    "    # creating folder to save model.h5 file\n",
    "    folder = 'model'\n",
    "    path_model = path_main +'/'+ folder\n",
    "    create_dir(path_model)\n",
    "\n",
    "    # creating folder to save model.h5 file\n",
    "    folder = 'model_checkpoint'\n",
    "    path_checkpoint = path_main +'/'+ folder\n",
    "    create_dir(path_checkpoint)\n",
    "\n",
    "    # initializing model\n",
    "    model_init = LSTM_model(n_hidden_layers, units, dropout, train_data_X, train_data_y, epochs)\n",
    "\n",
    "    # calling the model\n",
    "    model = model_init.build_model()\n",
    "\n",
    "    # metrics for evaluating the model\n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanAbsolutePercentageError()]\n",
    "\n",
    "    # model compiler\n",
    "    model.compile(optimizer=Adam(learning_rate = 0.0001), loss='mse', metrics = metrics)\n",
    "\n",
    "    # setting the model file name\n",
    "    model_name = 'lstm_'+ str(units)+'.h5'\n",
    "    \n",
    "    # setting the callback function\n",
    "    cb = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(path_checkpoint),\n",
    "        tf.keras.callbacks.CSVLogger(path_metrics+'/'+'data.csv'),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)]\n",
    "\n",
    "    # model fitting protocol\n",
    "    history = model.fit(train_data_X,train_data_y, \n",
    "                        epochs = epochs, \n",
    "                        batch_size = 8, \n",
    "                        validation_data=(X_val_data, y_val_data), \n",
    "                        verbose = 1,\n",
    "                        callbacks=[cb],\n",
    "                        shuffle= False)\n",
    "\n",
    "    # path to save model\n",
    "    model.save(path_model+'/'+model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 0.0373 - root_mean_squared_error: 0.1930 - mean_absolute_error: 0.1409 - mean_absolute_percentage_error: 32.2084\n",
      "\n",
      " Evaluation of Training dataset: \n",
      " train_loss: 0.037 \n",
      " RMSE: 0.193 \n",
      " MAE: 0.141 \n",
      " MAPE: 32.208\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, RMSE, MAE, MAPE = model.evaluate(train_data_X,train_data_y)\n",
    "print('\\n','Evaluation of Training dataset:','\\n','train_loss:',round(train_loss,3),'\\n','RMSE:',round(RMSE,3),'\\n', 'MAE:',round(MAE,3),'\\n','MAPE:',round(MAPE,3))\n",
    "print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - mean_absolute_error: 0.0619 - mean_absolute_percentage_error: 5.9192\n",
      "\n",
      " Evaluation of Validation dataset: \n",
      " train_loss: 0.014 \n",
      " val_RMSE: 0.119 \n",
      " val_MAE: 0.062 \n",
      " MAPE: 32.208\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_RMSE, val_MAE, val_MAPE = model.evaluate(X_val_data, y_val_data)\n",
    "print('\\n','Evaluation of Validation dataset:','\\n','train_loss:',round(val_loss,3),'\\n','val_RMSE:',round(val_RMSE,3),'\\n', 'val_MAE:',round(val_MAE,3),'\\n','MAPE:',round(MAPE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def metricplot(df, xlab, ylab_1,ylab_2, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function plots metric curves and saves it\n",
    "    to respective folder\n",
    "    inputs: df : pandas dataframe \n",
    "            xlab: x-axis\n",
    "            ylab_1 : yaxis_1\n",
    "            ylab_2 : yaxis_2\n",
    "            path: full path for saving the plot\n",
    "            \"\"\"\n",
    "    plt.figure()\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "    sns.lineplot(x = df[xlab], y = df[ylab_1])\n",
    "    sns.lineplot(x = df[xlab], y = df[ylab_2])\n",
    "    plt.xlabel('Epochs',fontsize = 12)\n",
    "    plt.ylabel(ylab_1,fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.legend([ylab_1,ylab_2], prop={\"size\":12})\n",
    "    plt.savefig(path+'/'+ ylab_1)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_met = pd.read_csv('../Model_Outputs/model_lstm/metrics/data.csv')\n",
    "data_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Model_Outputs/model_lstm/metrics'\n",
    "df = pd.read_csv('../Model_Outputs/model_lstm/metrics/data.csv')\n",
    "\n",
    "metricplot(df, 'epoch', 'loss','val_loss', path)\n",
    "metricplot(df, 'epoch', 'mean_absolute_error','val_mean_absolute_error', path)\n",
    "metricplot(df, 'epoch', 'mean_absolute_percentage_error','val_mean_absolute_percentage_error', path)\n",
    "metricplot(df, 'epoch', 'root_mean_squared_error','val_root_mean_squared_error', path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.now()\n",
    "today  = today.strftime('%Y%m%d')\n",
    "path = '../Model_Outputs/'+ today"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('deepL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b90cab7ea642421f44636989edaf96d86cb1abe354b45ce6eed3b362842c2584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
