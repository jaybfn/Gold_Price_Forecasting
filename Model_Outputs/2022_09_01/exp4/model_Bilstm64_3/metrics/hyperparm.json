{
    "lags": 1,
    "n_hidden_layers": 3,
    "batch_size": 8,
    "units": 64,
    "dropout": 0.2,
    "epochs": 200,
    "learning_rate": 0.0001,
    "reg_l1": 0.0,
    "reg_l2": 0.03
}